{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Julia Academy\n",
    "\n",
    "## Data Science Course\n",
    "\n",
    "# 10. Neural Networks in Julia\n",
    "\n",
    "**Huda Nassar**\n",
    "\n",
    "**Source:** https://github.com/JuliaAcademy/DataScience/blob/main/10.%20Neural%20Nets.ipynb\n",
    "\n",
    "We will look at how we can implement neural networks using the `Flux.jl` package in Julia, using the infamous MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Flux, Flux.Data.MNIST\n",
    "using Flux: onehotbatch, argmax, crossentropy, throttle\n",
    "using Base.Iterators: repeated\n",
    "using Images\n",
    "using Plots\n",
    "using StatsBase: sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at some of these images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = MNIST.images();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<table><tbody><tr><td style='text-align:center;vertical-align:middle; margin: 0.5em;border:1px #90999f solid;border-collapse:collapse'><img style='max-width: 100px; max-height:100px;display:inline' src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAHAAAABwCAAAAADji6uXAAAABGdBTUEAALGPC/xhBQAAAAFzUkdCAK7OHOkAAAAgY0hSTQAAeiYAAICEAAD6AAAAgOgAAHUwAADqYAAAOpgAABdwnLpRPAAAAhtJREFUaAW9wc+LpgMAB/DP5LuzorVCSllJy3UpccCF3fbARaRkXYz9C5yGdg/ye8tVbc6bMtrESWMScnBSTrZNqT2sA+tnNNLr8By0vc3zPu9sfT+fKIuyKIuyKIuyKIuyKIuyKIuyKIuyKIuyKIuyKIuyuEJHcRabOIv38JedRVmURVns0j48h5exF4/iMdyC1+wsyqIsymIX1nACB8zbZ1yURVmUxRJuxWk8jFVcwlX4E/txjcWiLMqiLCa6Gh/iboMPsI7gEjbwAM4bF2VRFmUxwXXYwD0Gr+Mll1vDXfjYuCiLsiiLCTbwCGZ4BW+Ydw7nLBZlURZlscBhHMYM7+NVbJv3EI7hBfxhZ1EWZVEWI27GOwY/4TS2zfsIR7CK7/C2nUVZlEVZjLgfdxisY8u8NRzBHnyBM8ZFWZRFWYx4ECtYwZcudydO4hmDH3EKF42LsiiLshjxLWYG12MVe3AIZ3AAM/yLZ7FpsSiLsiiLEZ/hZ9yIr/A1bsBBrGBm8CI2TRNlURZlMeICDuIb3Ib7zPsd75ouyqIsymKBX3EI9+Jp7McTBn/jKfxiuiiLsiiLCX7DFrbwPJ7ECr7HJ5YTZVEWZbGEvVjHDBfwuOVFWZRFWSzhFG43+AHnLS/KoizKYqJrcdT/PrU7URZlURYTbeNz3IQ38ZbdibIoi7KY6B8cx3FXJsqiLMqiLMqiLMqiLMqiLMr+A8vuTyV/WApRAAAAAElFTkSuQmCC\"></td><td style='text-align:center;vertical-align:middle; margin: 0.5em;border:1px #90999f solid;border-collapse:collapse'><img style='max-width: 100px; max-height:100px;display:inline' src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAHAAAABwCAAAAADji6uXAAAABGdBTUEAALGPC/xhBQAAAAFzUkdCAK7OHOkAAAAgY0hSTQAAeiYAAICEAAD6AAAAgOgAAHUwAADqYAAAOpgAABdwnLpRPAAAAdJJREFUaAW9wbFqVgcABtDT5ltCKdrBCN0cMlRFKDgFQcgL1KGoi4MUFDu6d9JBkQwuOjg4BBdDF3FsO8atzmbyAVpcUttI1Q53COEP/vcm5TsnyqIsyqIsyqIsyqIsyqIsyqIsRvoBj/CZwUO8wLppoizKoixGWMclfMRHg+u4hqtYNV6URVmUxRzf4gIW8BgvcAxLuIhz+Am3jBNlURZlMcdXWMATXMd7u37FM1zFOl6bL8qiLMpijt/wF3bw3l6/YBMrOIPX5ouyKIuyGGED98zawTvTRFmURVmM8KP9LWHJNFEWZVEWh3AaJ00TZVEWZXEIy6aLsiiLsjiEK6aLsiiLsvgfvMKmcaIsyqIsDugsvjF4gD+ME2VRFmVxQKdxFG/xu/GiLMqiLA7gS9w0eIlN40VZlEVZHMAqThm8MU2URVmUxUTH8b3BDu6aJsqiLMpihHv4wuAyjhj8ifPYMmsb/5gVZVEWZTHHCm5g0ayvcRu3zXqO78yKsiiLsphjE39j0a4P+Ndewed2vbG/KIuyKIsR7mAFJ/AztrBhr4tYNtjGffuLsiiLshhhDWs+7alxoizKoizKoizKoizKoizKoizKoizKoizKoizKouw/gbg7c+T4j3YAAAAASUVORK5C\"></td><td style='text-align:center;vertical-align:middle; margin: 0.5em;border:1px #90999f solid;border-collapse:collapse'><img style='max-width: 100px; max-height:100px;display:inline' src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAHAAAABwCAAAAADji6uXAAAABGdBTUEAALGPC/xhBQAAAAFzUkdCAK7OHOkAAAAgY0hSTQAAeiYAAICEAAD6AAAAgOgAAHUwAADqYAAAOpgAABdwnLpRPAAAAglJREFUaAW9wbGL1QUAB/CP+TVBEy4SLTlCJCL/BNfMxSEwyMOhUQeHplzabzjERQlqiyhxCAdBBKlAEHJwq8EQHKTFQTzjlIY6G97wuPe6e78n8v18oizKoizKoizKoizKoizKoizKoizKoizK4hV6G/uxA0fwGJdtFGVRFmXxEvbiuJGP8Y6RRSwae4TLNoqyKIuymNM2XMSS2fabFmVRFmUxpy+wZGsPsICvTIuyKIuymMNJnDPyHOexjjV8b+xvBKumRVmURVkMdBgX8Bb+wqf4yfyiLMqiLAbYgR9xwMgK7mIBa/jHcFEWZVEWM+zEN/jA2DKWjfyCS7hmmCiLsiiLGfbiM5v7EAfxOx6YLcqiLMpiDmu4Z+QqTuAwDuECTpgtyqIsymKGZ3iIX/EDrhtbwdc4bbgoi7IoixlW8R7W8cK0s1gyXJRFWZTFAP/a3Lr5RFmURVlMeB1HcMswu/Ga4aIsyqIsJlzCcXyEP2xtD67gDcNFWZRFWUw4g3XcxJe4aeQJ3jSyD5/gLPbhGe4YJsqiLMpiwp84gEV8Z+xnHPX/lrFimCiLsiiLCadwA7tsdNS0F7iCbw0XZVEWZTHhNvbgIo7hfWP3EfyGq3iKa+YTZVEWZbGJz7GAd409xHY89vKiLMqiLLawilWvVpRFWZRFWZRFWZRFWZRFWZRFWZRFWZT9B4gJSTsHiDrVAAAAAElFTkSuQmCC\"></td><td style='text-align:center;vertical-align:middle; margin: 0.5em;border:1px #90999f solid;border-collapse:collapse'><img style='max-width: 100px; max-height:100px;display:inline' src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAHAAAABwCAAAAADji6uXAAAABGdBTUEAALGPC/xhBQAAAAFzUkdCAK7OHOkAAAAgY0hSTQAAeiYAAICEAAD6AAAAgOgAAHUwAADqYAAAOpgAABdwnLpRPAAAAjxJREFUaAW9wT+I1QUAB/DPwZeuQ67EJaGSiCgwLoiIoFX7A0eDWYTSEAWVbkXUYtEWNLQ0uBTiTQUVtAXREkUFDmeUQye2aRgk0nCEwzX8hsfj3r33OuL7+URZlEVZlEVZlEVZlEVZlEVZlEVZlEVZlEVZlEVZlMV/dBz34k4s4ArexQ3zibIoi7KYYRmnsB+rWEYMFrCFs/jNfKIsyqIsZngTb5judbxqPlEWZVEWU9yFF437C9/jM6wZPI93cNVsURZlURZTvIz9Rq5gFecN1gyW8BQ+NluURVmUxRRf4DY8hgt4C+dNdqv5RFmURVlMcQ4vmeyQcRvmE2VRFmWxS0eM/IqvzSfKoizKYpe+w0mD+7EPl80WZVEWZbFLd2DB4FtcNp8oi7Ioiymew+N4AAcNNrCO49jCFn6y3Uc4ivtw1UiURVmUxQSH8R4exIJxK1gxbp/t7sEtOINVI1EWZVEWE3yJm438jA08iT22+8O4g3jE4B/joizKoiwm2MCKwTc4hsN4FHsMrmOvwWtYx+dYxAu4yWDTuCiLsiiLCdbwPhZwCOdwwMg1nMRRPIMlnMURLOJpgxv40Lgoi7Ioiwk+wCaexUM4YPAn1nECv+MCnsAylnDMyDW8jR+Ni7Ioi7LYwWmcxt243WAdfxv5Ba/gDBYNNvEDTuCi7aIsyqIsZriES3b2Ka5jLx7GaVy0syiLsiiL/8FXBp+YLcqiLMqiLMqiLMqiLMqiLMqiLMqiLMqiLMqiLMr+BbtmU7oDr8+lAAAAAElFTkSuQmCC\"></td><td style='text-align:center;vertical-align:middle; margin: 0.5em;border:1px #90999f solid;border-collapse:collapse'><img style='max-width: 100px; max-height:100px;display:inline' src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAHAAAABwCAAAAADji6uXAAAABGdBTUEAALGPC/xhBQAAAAFzUkdCAK7OHOkAAAAgY0hSTQAAeiYAAICEAAD6AAAAgOgAAHUwAADqYAAAOpgAABdwnLpRPAAAAhtJREFUaAW9wT+IlgUAB+Dnq5/UInGRBa4NQkvUUOSgEDQ0FNEN4nBEf+jPVERDBA4WBwVCQ8sNDUI1HQUOIlq0NAQ1hzQECebg1hCXFX4N7/AifN97n3fye54oi7Ioi7Ioi7Ioi7Ioi7Ioi7JY0RZeN7iMZ3DN7YuyKIuyWNEJzA1+xQO45vZFWZRFWezBCziK73AJX+Mvq4myKIuy2KNDOImTeB/P4Te7i7Ioi7LYgytYw0GDI9jG43YXZVEWZbGiM3jN4CtcxGkcNziE+/CnaVEWZVEWK9rEpltt4bjBYbyJT0yLsiiLstiHbTyCUwaP4gD+tVyURVmUxT7M8TnewIM4gY9w2XJRFmVRFvt0FTeMPsCG5aIsyqIs7oC7MDOYmRZlURZlcQfcxNxgblqURVmUxRL34h6L/YMdo7M4ZbBjWpRFWZTFEu9g02I/4Rxu4FPcb/StaVEWZVEWCxxA8LPBdYOjWMOTeAI38TYOGz2PbctFWZRFWSzwKh7Ci/gP1w2ewprRy3gad1tdlEVZlMUCZ/EN1vGZ0Y9u9T0u4JjVRVmURVks8Dd+wBl8iHO4ZDTDHK/gGP7AW/jY7qIsyqIslvgC63gMG9gwmmFudB7n8QteMi3KoizKYomrWMezRu/iYcwwxw7ew5cGv+O0aVEWZVEWE65gy2jL/kVZlEVZlEVZlEVZlEVZlEVZlEVZlEVZlEVZlEXZ//a9TuNGvj0QAAAAAElFTkSuQmCC\"></td><td style='text-align:center;vertical-align:middle; margin: 0.5em;border:1px #90999f solid;border-collapse:collapse'><img style='max-width: 100px; max-height:100px;display:inline' src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAHAAAABwCAAAAADji6uXAAAABGdBTUEAALGPC/xhBQAAAAFzUkdCAK7OHOkAAAAgY0hSTQAAeiYAAICEAAD6AAAAgOgAAHUwAADqYAAAOpgAABdwnLpRPAAAAgBJREFUaAW9wb+LlwUAB+Dn5AMiSCS2KAjqlqF23j8Q5NR6yEHU6GBLFNTqqKO4CKJBuBxI0OIPaBApJAgKhBocDmzwpn4QxlHL6/Ad5FDe7+t95fM8URZlURZlURZlURZlURZlURZlURZlURZlURZlURZlURZlURZl8QrexhoeYB8+wGkcsN0mzuK2F0VZlEVZTHQQd3AISxhsN3huL/7xclEWZVEWExzGtzjkRX/hHjZwC3/jKTa8XJRFWZTFHEdxEcdtdxO/4Br+MF2URVmUxYjduIgzGMzcxJqdi7Ioi7IYcRarGDDgET62mCiLsiiLEctm/sMGzuB/i4myKIuyGHHKzFM8xApWcMPORVmURVmMeICT2I81rJn52syv+AZX8cQ0URZlURYjvsQNXMHguXcx4BiO4VN8jnVsGRdlURZlMeJf/Ihl253APqziI7yJa9jCunFRFmVRFjvw0Mx9XMD3OIJlrBsXZVEWZbGgTXyCu1gyX5RFWZTFa3AKA342X5RFWZTFglawit9x33xRFmVRFgvYg69wHKvYNF+URVmUxQ69h+s4gu9w1zRRFmVRFhO9g+B9fIG3sAt/4jNsmSbKoizKYoKD+AFvmFnCgJ9wCb+ZLsqiLMpigie4jA9xFOewgcd45NVEWZRFWUx0HuctLsqiLMqiLMqiLMqeAVp7Tr4hH8adAAAAAElFTkSuQmCC\"></td><td style='text-align:center;vertical-align:middle; margin: 0.5em;border:1px #90999f solid;border-collapse:collapse'><img style='max-width: 100px; max-height:100px;display:inline' src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAHAAAABwCAAAAADji6uXAAAABGdBTUEAALGPC/xhBQAAAAFzUkdCAK7OHOkAAAAgY0hSTQAAeiYAAICEAAD6AAAAgOgAAHUwAADqYAAAOpgAABdwnLpRPAAAAh1JREFUaAW9wU/I33MAB/DXL2+rScqf7bCDm4RyQ8TFQcr0UIq5uMnheVLSHLaTshuhWTnsoignnsOQcHGwHNhhC4kTey7Dnix/kj+H72E9Pfk+n+eh9+sVZVEWZVEWZVEWZVEWZVEWZVEWZVEWZVEWZVEWZVEW/4PvcBTP4w/zoizKoix24A5ch/NYxfc4gtdw1rwoi7IoiwH7cCcewBJ24RL8jdP4zeQpPG1elEVZlMUWHsHLuMZmC3yKy3ELVrCKj/27KIuyKIsZt+I4duNHPINVG63jAB7GpdhrXpRFWZTFjCewGwu8h+M224eDJqfxiXlRFmVRFjOWcTeuxQF8ixdw3mQ/nsONOIN7cda8KIuyKIsZv+AGvIn9OIxDOIov8AoWOId7sGZrURZlURZb+BWPYgmHcT1WXPQlHsKaMVEWZVEWAy7gdXyEd3GzyU9YwtfGRVmURVlswxrWXXQllvGkcVEWZVEW27CEu2y0jPdxwpgoi7Ioi0G7cNDkK7yIY1jgEE4YE2VRFmUx6DLcbvIBXsXnOInb8CDesrUoi7Ioix04ZXLBZIE9xkRZlEVZDLrJZo+b/IVvjImyKIuyGHTGRo9hxeRZfGhMlEVZlMUOHMEVWOB3vGRclEVZlMWgP/EDrsYek89wH9aNi7Ioi7IY9DPuxzs4hbfxBs7ZniiLsiiLbTiJq/w3URZlURZlURZlURZlURZlUfYPHRlTKvMxdYgAAAAASUVORK5C\"></td><td style='text-align:center;vertical-align:middle; margin: 0.5em;border:1px #90999f solid;border-collapse:collapse'><img style='max-width: 100px; max-height:100px;display:inline' src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAHAAAABwCAAAAADji6uXAAAABGdBTUEAALGPC/xhBQAAAAFzUkdCAK7OHOkAAAAgY0hSTQAAeiYAAICEAAD6AAAAgOgAAHUwAADqYAAAOpgAABdwnLpRPAAAAWRJREFUaAW9waGuzmEAB+DH9nM2s0+1U1yBZIemSaIrEHU3cHYI7kIWzFQ2Y1NsgqmSKp2gnA2f8Ab1/76f/Z4nyqIsyqIsyqIsyqIsyqIsyqIsyqIsyqIsDnCCD3iGJ7aJsiiLsjjAXVzB3nZRFmVRFotu49S8KIuyKItFx9iZF2VRFmXxHzy3XZRFWZTFolv++WG7KIuyKItF9wyf8Md2URZlURYLjnBkeIrftouyKIuyWHCKE8Nnc6IsyqIsFtw0vMO5OVEWZVEWk3a4bniPC3OiLMqiLCbdxx3s8dK8KIuyKIsJV/EYe7zBN/OiLMqiLCbscGK4wC/zoizKoiwmXDNcwltroizKoiwmPDL8xEdroizKoiw2uowHhtf4Yk2URVmUxUYPccPwwrooi7Ioi42ODef4bl2URVmUxaRX+GpdlEVZlMVGZzhzuCiLsiiLsiiLsiiLsiiLsiiLsiiLsij7C4bmIjfLzD3MAAAAAElFTkSuQmCC\"></td></tr></tbody></table><div><small>(a vector displayed as a row to save space)</small></div>",
      "text/plain": "8-element Array{Array{Gray{Normed{UInt8,8}},2},1}:\n [Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); … ; Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0)]\n [Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); … ; Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0)]\n [Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); … ; Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0)]\n [Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); … ; Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0)]\n [Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); … ; Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0)]\n [Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); … ; Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0)]\n [Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); … ; Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0)]\n [Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); … ; Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0)]"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample(mnist, 8, replace=false)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While each image is represented as an 2-dimensional array, the elements are a non-standard numeric type. We want to convert these images to a floating point array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "Array{Gray{Normed{UInt8,8}},2}"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "typeof(mnist[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "60000-element Array{Array{Float32,2},1}:\n [0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n [0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n [0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n [0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n [0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n [0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n [0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n [0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n [0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n [0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n [0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n [0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n [0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n ⋮\n [0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n [0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n [0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n [0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n [0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n [0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n [0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n [0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n [0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n [0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n [0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n [0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_float32(X) = Float32.(X)\n",
    "fpt_imgs = to_float32.(mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "Array{Float32,2}"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "typeof(fpt_imgs[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will create some more helpful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorize(x) = x[:]\n",
    "vectorized_imgs = vectorize.(fpt_imgs);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's create our dataset as a matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(784, 60000)"
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = hcat(vectorized_imgs...)\n",
    "size(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a quick check, we can verify that this process has not lost any information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPwAAABUCAAAAACDjwU4AAAABGdBTUEAALGPC/xhBQAAACBjSFJNAAB6JgAAgIQAAPoAAACA6AAAdTAAAOpgAAA6mAAAF3CculE8AAAAAmJLR0QA/4ePzL8AAAHvSURBVHja7do9ixNhFIbhKyEs2CgqEgQRtljs1spCCxUCIvZWip0K/g0rwdrKwkJLUSsLKytdXEsXP0Bw0cJuQVAEQSuZZIswmbzmJZ5zV5kkB+5nnsNkCEOSJEmSJEmSJEmSLCW9eYZHPOAM72rH6ObZry1Wk9DhB+MHpznIo9bDJ9isIV3KM3TzocNPrP1Z1lqvU59Vjs75g9GJUp6hmw8dfmLtr/Ci9eRhrnKftwuXLuUZuvnQ4SfWfqYzcRd8qCFdyjN086HDN2u/znCWyX3g2cKNC3qGbj50+GbtL7Cn9diQVfBl4cYFPUM3Hzp8s/bHwJt2Y7cZ8p5vCzcu6Bm6+dDhB7uOX0399l7Oc5lz4CY7lbyLeIZuPnT43Wt/YOz1cfqMOMIKl+jzgw1+MuB1Pe8inqGbDx2++TP7DtfZYfvvO+v0+MV3tthgk+d85TP7WalhXNAzdPOhwzdX+xt84tTYZ9s8YYuXkzPXOMTHSsYFPUM3Hzr8xE3OrXYzI/CwnnQpz9DNhw4/6Dz5uLb6/J6hm8/wUcnwUel4te+xNsuDMbWY7hm6+dDhO6797yU5bdM9lyLCvyJ0+O739ie5V9t+Ts/QzYcO3/0mZymY7hm6+dDhu6z9Uy7W9i7iGbr50OGTJEmSJEn+S/4AJytb74YMh24AAAAASUVORK5CYII=",
      "text/plain": "28×84 reinterpret(Gray{Float64}, ::Array{Float64,2}):\n Gray{Float64}(0.0)  Gray{Float64}(0.0)  …  Gray{Float64}(0.0)\n Gray{Float64}(0.0)  Gray{Float64}(0.0)     Gray{Float64}(0.0)\n Gray{Float64}(0.0)  Gray{Float64}(0.0)     Gray{Float64}(0.0)\n Gray{Float64}(0.0)  Gray{Float64}(0.0)     Gray{Float64}(0.0)\n Gray{Float64}(0.0)  Gray{Float64}(0.0)     Gray{Float64}(0.0)\n Gray{Float64}(0.0)  Gray{Float64}(0.0)  …  Gray{Float64}(0.0)\n Gray{Float64}(0.0)  Gray{Float64}(0.0)     Gray{Float64}(0.0)\n Gray{Float64}(0.0)  Gray{Float64}(0.0)     Gray{Float64}(0.0)\n Gray{Float64}(0.0)  Gray{Float64}(0.0)     Gray{Float64}(0.0)\n Gray{Float64}(0.0)  Gray{Float64}(0.0)     Gray{Float64}(0.0)\n Gray{Float64}(0.0)  Gray{Float64}(0.0)  …  Gray{Float64}(0.0)\n Gray{Float64}(0.0)  Gray{Float64}(0.0)     Gray{Float64}(0.0)\n Gray{Float64}(0.0)  Gray{Float64}(0.0)     Gray{Float64}(0.0)\n ⋮                                       ⋱  \n Gray{Float64}(0.0)  Gray{Float64}(0.0)     Gray{Float64}(0.0)\n Gray{Float64}(0.0)  Gray{Float64}(0.0)     Gray{Float64}(0.0)\n Gray{Float64}(0.0)  Gray{Float64}(0.0)     Gray{Float64}(0.0)\n Gray{Float64}(0.0)  Gray{Float64}(0.0)     Gray{Float64}(0.0)\n Gray{Float64}(0.0)  Gray{Float64}(0.0)  …  Gray{Float64}(0.0)\n Gray{Float64}(0.0)  Gray{Float64}(0.0)     Gray{Float64}(0.0)\n Gray{Float64}(0.0)  Gray{Float64}(0.0)     Gray{Float64}(0.0)\n Gray{Float64}(0.0)  Gray{Float64}(0.0)     Gray{Float64}(0.0)\n Gray{Float64}(0.0)  Gray{Float64}(0.0)     Gray{Float64}(0.0)\n Gray{Float64}(0.0)  Gray{Float64}(0.0)  …  Gray{Float64}(0.0)\n Gray{Float64}(0.0)  Gray{Float64}(0.0)     Gray{Float64}(0.0)\n Gray{Float64}(0.0)  Gray{Float64}(0.0)     Gray{Float64}(0.0)"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_sample = X[:,3]\n",
    "x_sample = reshape(x_sample, 28, 28)\n",
    "colorview(Gray, hcat(x_sample, zeros(size(x_sample)), mnist[3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's get the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "4"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = MNIST.labels()\n",
    "labels[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One-hot encode the labels as an indicator vector where the correct label is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "10×60000 Flux.OneHotMatrix{Array{Flux.OneHotVector,1}}:\n 0  1  0  0  0  0  0  0  0  0  0  0  0  …  0  0  0  0  0  0  0  0  0  0  0  0\n 0  0  0  1  0  0  1  0  1  0  0  0  0     0  0  0  0  0  0  1  0  0  0  0  0\n 0  0  0  0  0  1  0  0  0  0  0  0  0     0  0  0  1  0  0  0  0  0  0  0  0\n 0  0  0  0  0  0  0  1  0  0  1  0  1     0  0  0  0  0  0  0  0  1  0  0  0\n 0  0  1  0  0  0  0  0  0  1  0  0  0     0  0  0  0  0  0  0  0  0  0  0  0\n 1  0  0  0  0  0  0  0  0  0  0  1  0  …  0  0  0  0  0  1  0  0  0  1  0  0\n 0  0  0  0  0  0  0  0  0  0  0  0  0     0  0  0  0  0  0  0  0  0  0  1  0\n 0  0  0  0  0  0  0  0  0  0  0  0  0     1  0  0  0  0  0  0  0  0  0  0  0\n 0  0  0  0  0  0  0  0  0  0  0  0  0     0  1  0  0  0  0  0  1  0  0  0  1\n 0  0  0  0  1  0  0  0  0  0  0  0  0     0  0  1  0  1  0  0  0  0  0  0  0"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = onehotbatch(labels, 0:9)  # in MNIST, 0 is the first digit, and 9 is the 10th digit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "Chain(Dense(784, 32, relu), Dense(32, 10), softmax)"
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nnetwork = Chain(\n",
    "    Dense(28^2, 32, relu),\n",
    "    Dense(32, 10),\n",
    "    softmax\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a check, how does this neural network transform its input? Why it takes a Julia array and outputs a Julia array (Julia all the way down)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "10-element Array{Float32,1}:\n 0.14534412\n 0.09707237\n 0.08854742\n 0.10480764\n 0.10673808\n 0.07622286\n 0.07558342\n 0.10789169\n 0.13588229\n 0.0619101"
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nnetwork(vectorize(x_sample))  # remember we reshaped x_sample, so we vectorize again"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    " loss(x, y) = crossentropy(nnetwork(x), y)\n",
    " accuracy(x, y) = mean(argmax(nnetwork(x)) .== argmax(y));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create an eval function callback to display during the loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_callback = () -> @show(loss(X, Y));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To improve accuracy, we'll repeat the dataset so we have more samples to pass through the training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = repeated((X,Y), 200);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's define an optimizer. We'll use ADAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "ADAM(0.001, (0.9, 0.999), IdDict{Any,Any}())"
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt = Flux.ADAM()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to get the trainable params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "θ = Flux.params(nnetwork);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now begin the training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss(X, Y) = 2.3087978f0\n",
      "loss(X, Y) = 1.3257898f0\n",
      "loss(X, Y) = 0.75609374f0\n",
      "loss(X, Y) = 0.5688039f0\n",
      "loss(X, Y) = 0.48491055f0\n",
      "loss(X, Y) = 0.43222213f0\n",
      "loss(X, Y) = 0.39523432f0\n",
      "loss(X, Y) = 0.3674953f0\n",
      "loss(X, Y) = 0.34715715f0\n",
      "loss(X, Y) = 0.3303771f0\n",
      "loss(X, Y) = 0.31512728f0\n",
      "loss(X, Y) = 0.30376446f0\n",
      "loss(X, Y) = 0.2920162f0\n",
      "loss(X, Y) = 0.28224936f0\n"
     ]
    }
   ],
   "source": [
    "Flux.train!(loss, θ, dataset, opt, cb=throttle(loss_callback, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test set evaluation\n",
    "\n",
    "Now that the network is trained, we can try it on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = MNIST.images(:test)\n",
    "test_set = hcat(float.(reshape.(test_images, :))...);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAHAAAABwCAAAAADji6uXAAAABGdBTUEAALGPC/xhBQAAACBjSFJNAAB6JgAAgIQAAPoAAACA6AAAdTAAAOpgAAA6mAAAF3CculE8AAAAAmJLR0QA/4ePzL8AAAGrSURBVGje7dk/a9VQHIfxT711EFysKDhYOzl0KSKCoILiYtuhg30L10U7dnZ3dPAddBEEQRERKuigDl1E7T+8HVREEOqghaKFOiRDKVy9aUp78uN8l5z8IQ8PX06SQ8jJycnJycnJycnJyamfvm4nJtHGV6xjBt/wsSbwwF4bxgd27XAFQ9uO/cSH/9zwC+5gLhXD+MD+bifaGME8hnEGl3Een3Fyy7Ub+I4T5f4nucM9TF+Vi48oupzDuS3H17GMBQzgFu6lYhgfWKnDf+U67uM9rmA1FcP4wF3p8DjeldtJPEjJMD6wv/4tuIlj+IGl1AzjA2vPwwt4joOKb56XqRnGB9aeh2OK/mbxOkXD+MBaHR7CNfzGbfxJ0TA+sFaH04q1xlO8StUwPnDH78NxPMQaRvX2HN0Xw/jAHc3Do7iLFp7ovb99MYwPrDwPW3iDs+go3oedlA3jAyt3eBqL5XgCj1I3jA+s9Cw9hWfleBqPm2AYH1ipwxsYLMcvsNkEw/jAnju8hKkmGsYH9tzhRRwuxx38aophfGDltcVbXNX931JyhvGBOc3PX/q9Oc17OzXKAAAAAElFTkSuQmCC",
      "text/plain": "28×28 Array{Gray{Float32},2} with eltype Gray{Float32}:\n Gray{Float32}(0.0)  Gray{Float32}(0.0)  …  Gray{Float32}(0.0)\n Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n Gray{Float32}(0.0)  Gray{Float32}(0.0)  …  Gray{Float32}(0.0)\n Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n Gray{Float32}(0.0)  Gray{Float32}(0.0)  …  Gray{Float32}(0.0)\n Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n ⋮                                       ⋱  \n Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n Gray{Float32}(0.0)  Gray{Float32}(0.0)  …  Gray{Float32}(0.0)\n Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n Gray{Float32}(0.0)  Gray{Float32}(0.0)  …  Gray{Float32}(0.0)\n Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)"
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_test_img = test_set[:,1]\n",
    "colorview(Gray, reshape(sample_test_img, 28, 28))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try the neural network on this sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "10-element Array{Float32,1}:\n 0.0017408056\n 3.1085149f-6\n 0.0001689861\n 0.0028648733\n 2.3184602f-5\n 0.00013410702\n 6.2928257f-6\n 0.99366546\n 8.290674f-5\n 0.0013103124"
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test softmax distribution\n",
    "sample_output = nnetwork(sample_test_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "7"
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_pred_label = argmax(sample_output) - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yay, it worked. Now let's try the image we tried earlier on the default initialized parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "4"
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "argmax( nnetwork(vectorize(x_sample)) ) - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perfect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "32×784 Array{Float32,2}:\n -0.0326841    0.0828       0.0759793    …   0.0293909   -0.0766047\n  0.00162051  -0.0386024    0.0538956       -0.00874778  -0.0546198\n -0.00363952  -0.0823463    0.00859579      -0.0259495    0.0845862\n  0.0791014    0.0395332   -0.0481769       -0.0637125   -0.0622999\n  0.073427    -0.0341381    0.00868462       0.0405414    0.077878\n  0.0161403   -0.021042    -0.00310758   …   0.044178     0.0529863\n  0.0715785   -0.0376605   -0.0054879        0.0683997    0.0801135\n -0.00314577  -0.0263821   -0.0628713        0.00285861   0.00462587\n  0.00467905  -0.0546417    0.0166793        0.0676102    0.0092139\n  0.0206162   -0.0737192   -0.0324265       -0.063325     0.0775277\n -0.0134303   -0.076986    -0.0310222    …  -0.0232476   -0.0284026\n  0.0350498    0.0763622   -0.0306058        0.0136959    0.0102355\n -0.0315415   -0.0235403    0.0471421        0.0678656    0.0564892\n  ⋮                                      ⋱               \n  0.0140613    0.00987587  -0.0640072    …  -0.0568149    0.0380036\n -0.0204847   -0.0389352   -0.0469337       -0.00707949  -0.0148061\n  0.00836753  -0.0219879    0.0194783       -0.0158416   -0.0663453\n -0.0600526   -0.0317524   -0.0224876       -0.0575563   -0.0689594\n  0.00996721   0.0321931   -0.0687312        0.0111531    0.0179738\n  0.0487715   -0.0360919    0.0757781    …  -0.00306375   0.0565703\n  0.0134153    0.0780733    0.0823932       -0.00749788   0.0301854\n -0.0673342    0.0777298    0.0393485       -0.0190938   -0.0324253\n  0.0852381    0.0228383    0.0182068       -0.0598672    0.0315868\n  0.0419861    0.0201995   -0.000349678     -0.0559287   -0.0149718\n -0.0452012    0.0281404   -0.00743644   …  -0.0248298    0.00659232\n  0.0834116    0.0539924    0.0592823        0.0567342    0.0514605"
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "θ[1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.5.3",
   "language": "julia",
   "name": "julia-1.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.5.3"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}