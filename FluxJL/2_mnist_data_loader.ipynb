{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flux JL\n",
    "\n",
    "## Flux Model Zoo Examples\n",
    "\n",
    "# 2. Flux DataLoader Tutorial for MNIST \n",
    "\n",
    "**FluxML contributors**\n",
    "\n",
    "**Source:** https://github.com/FluxML/model-zoo/tree/master/tutorials/dataloader\n",
    "\n",
    "In this notebook we will go over a trivial example of how dataloaders work in Flux.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using MLDatasets: MNIST\n",
    "using Flux.Data: DataLoader\n",
    "using Flux: onehotbatch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Load MNIST data into memory\n",
    "\n",
    "MNIST is small enough to fit into memory. We will load the whole train and test datasets using Float32 precision. Since stochastic gradient descent is an approximation of the true gradients, we can trade off precision (which doesn't even matter owing to the variance and convergence properties of the algorithm) for more efficient performance.\n",
    "\n",
    "In total the train dataset consists of 60000 28x28 images (in grayscale). The labels are a vector consisting of the integer (as Float32) value of the actual handwritten digit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y = MNIST.traindata(Float32)\n",
    "test_x, test_y = MNIST.testdata(Float32)\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Pipe dataset through a DataLoader\n",
    "\n",
    "Before we can use the MNIST data in a machine learning model, we need to reshape the data into a format that makes sense for the mathematical operations of the neural network. \n",
    "* The shape of the data is 28 $\\times$ 28 $\\times$ 60000 which follows a WHB format (width $\\times$ height $\\times$ batch size). \n",
    "* For convolutional neural networks we will prefer a WHCB format (width $\\times$ height $\\times$ no. of channels $\\times$ batch size)\n",
    "* Since the data is grayscale, the number of channels is just one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(28, 28, 60000)"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = reshape(train_x, 28, 28, 1, :)\n",
    "test_x = reshape(test_x, 28, 28, 1, :)\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Secondly we will encode the labels as *one-hot* vectors to match the expected output dimensions of the convolutional neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = onehotbatch(train_y, 0:9) \n",
    "test_y = onehotbatch(test_y, 0:9)\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a summary of what we have just done, let's inspect the first sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "28×28×1 Array{Float32,3}:\n[:, :, 1] =\n 0.0  0.0  0.0  0.0  0.0  0.0        …  0.0       0.0        0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0           0.0       0.0        0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0           0.0       0.0        0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0           0.0       0.0        0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0           0.215686  0.533333   0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0        …  0.67451   0.992157   0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0           0.886275  0.992157   0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0           0.992157  0.992157   0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0           0.992157  0.831373   0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0           0.992157  0.529412   0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0        …  0.992157  0.517647   0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0           0.956863  0.0627451  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0117647     0.521569  0.0        0.0  0.0  0.0\n ⋮                        ⋮          ⋱                       ⋮         \n 0.0  0.0  0.0  0.0  0.0  0.494118      0.0       0.0        0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.533333      0.0       0.0        0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.686275      0.0       0.0        0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.101961      0.0       0.0        0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.65098    …  0.0       0.0        0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  1.0           0.0       0.0        0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.968627      0.0       0.0        0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.498039      0.0       0.0        0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0           0.0       0.0        0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0        …  0.0       0.0        0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0           0.0       0.0        0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0           0.0       0.0        0.0  0.0  0.0"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x[:,:,:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What number is this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "10-element Flux.OneHotVector:\n 0\n 0\n 0\n 0\n 0\n 1\n 0\n 0\n 0\n 0"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is a $5$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now create a data loader for the train and test sets. This is an iterable which we will be able to iterate over during training and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_x, train_y, batchsize=128, shuffle=true)\n",
    "test_dataloader = DataLoader(test_x, test_y)\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Iterating over the dataset\n",
    "\n",
    "The dataloaders are iterables which split the dataset into fixed batch sizes (except for the last which may contain remainders). The dataloaders can be iterated over during the training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (x,y) in train_dataloader\n",
    "    @assert size(x) == (28, 28, 1, 128) || size(x) == (28, 28, 1, 96)\n",
    "    @assert size(y) == (10, 128) || size(y) == (10, 96)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.5.3",
   "language": "julia",
   "name": "julia-1.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.5.3"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}