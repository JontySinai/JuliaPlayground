{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flux JL\n",
    "\n",
    "## Flux Model Zoo Examples\n",
    "\n",
    "# 4. Char RNN\n",
    "\n",
    "**FluxML contributors**\n",
    "\n",
    "**Source:** https://github.com/FluxML/model-zoo/blob/master/text/char-rnn/char-rnn.jl\n",
    "\n",
    "In this notebook we will do a hello world model of a sequential neural network, ie. the Char RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Flux\n",
    "using Flux: onehot, onecold, chunk, batchseq, throttle, logitcrossentropy\n",
    "using StatsBase: wsample\n",
    "using Statistics, Random\n",
    "using Base.Iterators: partition\n",
    "using Parameters: @with_kw\n",
    "using ProgressMeter: @showprogress\n",
    "using Logging: with_logger\n",
    "using CUDA\n",
    "import BSON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_params(model) = sum(length, Flux.params(model)) \n",
    "round4(x) = round(x, digits=4)\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Char RNN\n",
    "\n",
    "We'll start with the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "CharRNN (generic function with 1 method)"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function CharRNN(N; hidden_dimsize=128)\n",
    "    return Chain(\n",
    "            LSTM(N, hidden_dimsize),\n",
    "            LSTM(hidden_dimsize, hidden_dimsize),\n",
    "            Dense(hidden_dimsize, N))\n",
    "end "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataloader\n",
    "\n",
    "We'll use Shakespeare text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "get_data (generic function with 1 method)"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function get_data(nbatches, seqlen)\n",
    "    stopchar = '_'\n",
    "\n",
    "    # Get the data if not downloaded already\n",
    "    isfile(\"shakespeare_input.txt\") ||\n",
    "        download(\"https://cs.stanford.edu/people/karpathy/char-rnn/shakespeare_input.txt\",\"shakespeare_input.txt\")\n",
    "\n",
    "    text = collect(String(read(\"shakespeare_input.txt\")))\n",
    "    \n",
    "    # Construct an alphabet of the unique characters\n",
    "    alphabet = [unique(text)..., stopchar]\n",
    "    \n",
    "    text_data = map(ch -> onehot(ch, alphabet), text)\n",
    "    stopseq = onehot(stopchar, alphabet)\n",
    "    \n",
    "    # Partition the data as sequence of batches, which are then collected as array of batches\n",
    "    Xs = collect(partition(batchseq(chunk(text_data, nbatches), stopseq), seqlen))\n",
    "    Ys = collect(partition(batchseq(chunk(text_data[2:end], nbatches), stopseq), seqlen))\n",
    "\n",
    "    nsamples = length(text)\n",
    "\n",
    "    evalseqs = Xs[5], Ys[5]\n",
    "    dataloader = zip(Xs, Ys)\n",
    "\n",
    "    return dataloader, evalseqs, alphabet, nsamples\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "loss (generic function with 1 method)"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function loss(ŷs, ys)\n",
    "    return sum(logitcrossentropy.(ŷs, ys))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "evaluate (generic function with 1 method)"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function evaluate(evalseqs, model, device)\n",
    "    xtest, ytest = evalseqs[1] |> device, evalseqs[2] |> device\n",
    "    ŷtest = model.(xtest)\n",
    "\n",
    "    l = loss(ŷtest, ytest) |> round4\n",
    "    \n",
    "    acc_counter = 0\n",
    "    n_counter = 0\n",
    "    for (ŷ, y) in zip(ŷtest, ytest)\n",
    "        acc_counter += sum(onecold(ŷ |> cpu) .== onecold(y |> cpu))\n",
    "        n_counter += size(ŷ)[end]\n",
    "    end\n",
    "    acc = 100 * (acc_counter / n_counter) |> round4\n",
    "\n",
    "    return (loss=l, accuracy=acc)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "train (generic function with 1 method)"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function train(; kws...)\n",
    "    args = Args(; kws...)\n",
    "    args.seed > 0 && Random.seed!(args.seed)\n",
    "    use_cuda = args.use_cuda && CUDA.functional()\n",
    "\n",
    "    if use_cuda\n",
    "        device = gpu\n",
    "        @info \"Training on GPU\"\n",
    "    else\n",
    "        device = cpu\n",
    "        @info \"Training on CPU\"\n",
    "    end\n",
    "    \n",
    "    ## Data\n",
    "    dataloader, evalseqs, alphabet, nsamples = get_data(args.nbatches, args.seqlen)\n",
    "    nchars = length(alphabet)\n",
    "    @info \"Shakespeare dataset: $nsamples samples and $nchars unique chars in alphabet\"\n",
    "\n",
    "    ## Model\n",
    "    model = CharRNN(nchars) |> device\n",
    "    @info \"Char RNN LSTM model: $(num_params(model)) trainable params\" \n",
    "    \n",
    "    ## Optimiser\n",
    "    θ = Flux.params(model)\n",
    "    optimiser = ADAM(args.η)\n",
    "\n",
    "    ## Epoch logging\n",
    "    function report(epoch)\n",
    "        eval = evaluate(evalseqs, model, device)    \n",
    "        println(\"Epoch: $epoch   Eval: $(eval)\")\n",
    "    end\n",
    "\n",
    "    ## Training Loop\n",
    "    @info \"Training started ...\"\n",
    "    report(0)\n",
    "    for epoch in 1:args.epochs\n",
    "        @showprogress for (xs, ys) in dataloader\n",
    "            xs, ys = xs |> device, ys |> device\n",
    "            ∂loss = Flux.gradient(θ) do\n",
    "                        ŷs = model.(xs)\n",
    "                        loss(ŷs, ys)\n",
    "                    end\n",
    "            \n",
    "            Flux.Optimise.update!(optimiser, θ, ∂loss)\n",
    "        end\n",
    "\n",
    "        ## Printing and logging\n",
    "        epoch % args.infotime == 0 && report(epoch)\n",
    "        if args.checktime > 0 && epoch % args.checktime == 0\n",
    "            !ispath(args.savepath) && mkpath(args.savepath)\n",
    "            modelpath = joinpath(args.savepath, \"model.bson\") \n",
    "            let model = cpu(model) #return model to cpu before serialization\n",
    "                BSON.@save modelpath model epoch\n",
    "            end\n",
    "            @info \"Model saved in \\\"$(modelpath)\\\"\"\n",
    "        end\n",
    "    end\n",
    "\n",
    "\n",
    "    return model, alphabet\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Programme Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "Args"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@with_kw mutable struct Args\n",
    "    seed::Int = 0               # set seed > 0 for reproducibility\n",
    "    use_cuda::Bool = false      # if true use cuda (if available)\n",
    "    η::Float64 = 1e-2\t        # Learning rate\n",
    "    epochs::Int = 5             # Number of epochs\n",
    "    seqlen::Int = 50\t        # Length of batchseqences\n",
    "    nbatches::Int = 50\t        # Number of batches text is divided into\n",
    "    infotime::Int = 1 \t        # report every `infotime` epochs\n",
    "    checktime::Int = 1          # Save the model every `checktime` epochs. Set to 0 for no checkpoints\n",
    "    savepath::String = \"runs/char_rnn\"    # results path\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Training on CPU\n",
      "└ @ Main In[17]:11\n",
      "┌ Info: Shakespeare dataset: 4573338 samples and 68 unique chars in alphabet\n",
      "└ @ Main In[17]:17\n",
      "┌ Info: Char RNN LSTM model: 241732 trainable params\n",
      "└ @ Main In[17]:21\n",
      "┌ Info: Training started ...\n",
      "└ @ Main In[17]:34\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0   Eval: (loss = 211.0863f0, accuracy = 1.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:13:19\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1   Eval: (loss = 114.1595f0, accuracy = 35.84)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Model saved in \"runs/char_rnn/model.bson\"\n",
      "└ @ Main In[17]:55\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:13:06\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2   Eval: (loss = 110.1661f0, accuracy = 38.28)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Model saved in \"runs/char_rnn/model.bson\"\n",
      "└ @ Main In[17]:55\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:13:24\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3   Eval: (loss = 109.7231f0, accuracy = 37.48)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Model saved in \"runs/char_rnn/model.bson\"\n",
      "└ @ Main In[17]:55\n"
     ]
    },
    {
     "data": {
      "text/plain": "(Chain(Recur(LSTMCell(68, 128)), Recur(LSTMCell(128, 128)), Dense(128, 68)), ['F', 'i', 'r', 's', 't', ' ', 'C', 'z', 'e', 'n'  …  'K', 'Q', '&', 'Z', 'X', '3', '$', '[', ']', '_'])"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm, alphabet = train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.6.2",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "name": "julia",
   "version": ""
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}